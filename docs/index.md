---
title: 'Jupyter notebooks as quiz question source files'
---

## Background

In the worst case scenario, my work-flow for posting a quiz on canvas used to involve four separate source documents:

1. A docx file containing quiz questions with answers/explanations. 
1. A separate docx file with the answers stripped that was posted for students to work from
   prior to entering their answers on canvas.

1. A jupyter python notebook with the numeric answers worked out

1. A canvas quiz with the question entered via the canvas web interface

Fortunately, three of these documents are unnecessary.  My current workflow is:

1. Write a [jupyter notebook](https://jupyter.org/) with the quiz questions and answers. This is a mix of markdown cells for the narrative/images, and python cells for the actual calculations.  Use
   jupyter cell metadata to tag each cell as a question or answer, along with the question number and, if
   multiple choice, the correct answer.

1. Save the notebook as a python file using [jupytext](https://github.com/mwouts/jupytext)  (This is automatic, since the jupytext plug-in overrides jupyter's `content_manager_class`).

1. Commit to git

1. Generate the student version of the quiz by filtering out the answer cells and use `jupyter nbconvert` to produce a paginated pdf with headers.

1. (to be done) Generate the canvas version of the quiz using the [r-exams](http://www.r-exams.org/)
canvas QTI writer.

For classes that involve student programming, we've adopted DSCI 100's use of  [nbgrader](https://nbgrader.readthedocs.io/en/stable/), which as you know is just a (much) more elaborate version of the work-flow above.

## Example

* Here is the final pdf version of a quiz solution:  [quiz2_answers.pdf](
https://www.dropbox.com/s/0j6pw4obeep7v5x/quiz2_answers.pdf?dl=0)

* Here is the jupytext python version of that notebook:  [quiz2_answers.py](https://github.com/eoas-ubc/nbpython/blob/master/notebooks/quiz2_2019t1.py#L98)

* Here is a python function to strip all answer cells from the student version: [strip_answers](https://github.com/eoas-ubc/nbpython/blob/master/e340lib/noteutils.py#L12), which is called from the command line with [strip_answers.py](https://github.com/eoas-ubc/nbpython/blob/master/e340lib/strip_answers.py)


* We can also re-order cells to produce B and C versions of an in-class quiz, and automatically generate Remark grading keys from the cell answer metadata


## Workflow for clicker questions

There is a similar single source problem for clicker questions, which currently exist in 3 distinct powerpoint versions:

1. The original question with the clicker choices and the answer

1. The posted pre-class version, which has the question but omits the choices

1. The posted post-class version, which has the question and the choices, but not the answer

All of these can be generated by a single jupyter notebook, and written to powerpoint using [python-pptx](https://python-pptx.readthedocs.io/en/latest/)

## Output for Canvas and PrairieLearn

As mentioned above -- we can upload quiz questions in QTI format using [r-exams](http://www.r-exams.org/).  It should be fairly simple to write similar post-processing code to turn a notebook markdown question into a format importable into PrairieLearn.


## Summary

Life is better if your quiz question bank is:

1. The sole source of all versions of the quiz

1. Executable so you can generate multiple versions of a question (ala r-exams)

1. Written in markdown instead of a combination of docx and pptx

1. Searchable by simple tools like grep

1. Version controlled with git

1. Autogradable (nbgrader)








